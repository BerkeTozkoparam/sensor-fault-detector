# -*- coding: utf-8 -*-
"""Sensör verisi hata sınıflandırılması

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17QXGIVfhm6NUP7wkX_G0zg57_Bluuq13
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings

# warnings'i kapat
warnings.filterwarnings('ignore')

# 1. Veriyi Yükle
file_path = '/content/sensor_maintenance_data.csv'
df = pd.read_csv(file_path)

# 2. Özellik (X) ve Hedef (y) Belirleme
target_column = 'Failure Type'

# -------- DÜZELTME BURADA --------
# 'nan' olarak okunan boş değerleri (None) 'None' metniyle doldur.
y = df[target_column].fillna('None')
# ---------------------------------

# 3. Veri Sızıntısını ve Alakasız Sütunları Ayıklama
columns_to_drop = [
    target_column,
    'Fault Detected',
    'Fault Status',
    'Predictive Maintenance Trigger',
    'Repair Time (hrs)',
    'Maintenance Costs (USD)',
    'Sensor_ID',
    'Equipment_ID',
    'Timestamp',
    'Last Maintenance Date'
]

X = df.drop(columns=columns_to_drop)

# Kategorik ve Sayısal Sütunları Otomatik Olarak Belirle
numerical_cols = X.select_dtypes(include=np.number).columns
categorical_cols = X.select_dtypes(include=['object', 'category']).columns

print(f"--- Modelde Kullanılacak Sütunlar ({len(X.columns)}) ---")
print(f"Sayısal Sütunlar ({len(numerical_cols)}): {list(numerical_cols)}")
print(f"Kategorik Sütunlar ({len(categorical_cols)}): {list(categorical_cols)}")
print("--------------------------------------------------\n")


# HEDEF DEĞİŞKENİ (y) ENCODE ETME
le = LabelEncoder()
y_encoded = le.fit_transform(y)
class_names = le.classes_
print(f"Hedef Sınıflar: {list(class_names)}") # Artık burada 'nan' görmemeliyiz
print(f"Encode Edilmiş Hali: {list(range(len(class_names)))}\n")


# 4. Veri Ön İşleme (Preprocessing) Pipeline'ı Kurma
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# 5. Model Eğitimi (Pipeline içinde)
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded,
    test_size=0.2,
    random_state=42,
    stratify=y_encoded
)

# MODEL: RandomForestClassifier kullan
model_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(
        n_estimators=100,
        random_state=42,
        class_weight='balanced'
    ))
])

# Modeli Eğit
print("RandomForest modeli eğitiliyor...")
model_pipeline.fit(X_train, y_train)
print("Model eğitimi tamamlandı.\n")


# 6. Değerlendirme
print("--- MODEL DEĞERLENDİRME (Test Verisi) ---")
y_pred = model_pipeline.predict(X_test)

# Doğruluk (Accuracy)
accuracy = accuracy_score(y_test, y_pred)
print(f"Genel Doğruluk (Accuracy): {accuracy:.4f}")
print("--------------------------------------------------\n")

# Sınıflandırma Raporu (Precision, Recall, F1-Score)
y_test_labels = le.inverse_transform(y_test)
y_pred_labels = le.inverse_transform(y_pred)

print("Sınıflandırma Raporu (Classification Report):")
print(classification_report(y_test_labels, y_pred_labels, target_names=class_names)) # Bu satır artık çalışmalı
print("\n--------------------------------------------------\n")

# Karışıklık Matrisi (Confusion Matrix)
print("Karışıklık Matrisi (Confusion Matrix):")
print("Tahmin Edilen ->")
cm = confusion_matrix(y_test_labels, y_pred_labels, labels=class_names)
cm_df = pd.DataFrame(cm, index=[f"Gerçek: {cls}" for cls in class_names], columns=[f"Tahmin: {cls}" for cls in class_names])
print(cm_df)

import joblib
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# --- Bu değişkenlerin bir önceki koddan geldiğini varsayıyoruz ---
# model_pipeline = ... (eğitilmiş pipeline)
# le = ... (eğitilmiş LabelEncoder)
# -----------------------------------------------------------------

# 1. Model pipeline'ını kaydet
joblib.dump(model_pipeline, 'sensor_model_pipeline.joblib')
print("Model pipeline'ı 'sensor_model_pipeline.joblib' olarak kaydedildi.")

# 2. LabelEncoder'ı kaydet
joblib.dump(le, 'label_encoder.joblib')
print("LabelEncoder 'label_encoder.joblib' olarak kaydedildi.")

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, RocCurveDisplay, precision_recall_curve, PrecisionRecallDisplay
from sklearn.preprocessing import label_binarize

# -----------------------------------------------
# 1. ROC Eğrisi (One-vs-Rest)
# -----------------------------------------------
y_test_bin = label_binarize(y_test, classes=range(len(class_names)))
y_score = model_pipeline.predict_proba(X_test)  # Çoklu sınıf için predict_proba gerekli

plt.figure(figsize=(10, 8))
for i in range(len(class_names)):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=1)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Eğrisi (Multi-class)')
plt.legend(loc="lower right")
plt.show()


# -----------------------------------------------
# 2. Confusion Matrix Görselleştirme
# -----------------------------------------------
import seaborn as sns

plt.figure(figsize=(10, 8))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')
plt.title('Karışıklık Matrisi (Confusion Matrix)')
plt.ylabel('Gerçek Sınıf')
plt.xlabel('Tahmin Edilen Sınıf')
plt.show()


# -----------------------------------------------
# 3. Feature Importance (Random Forest)
# -----------------------------------------------
# Pipeline'dan classifier'ı alıyoruz
clf = model_pipeline.named_steps['classifier']

# Sayısal ve one-hot encode edilmiş kategorik sütunları birleştirme
feature_names = list(numerical_cols)
if len(categorical_cols) > 0:
    ohe = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']
    cat_features = ohe.get_feature_names_out(categorical_cols)
    feature_names.extend(cat_features)

importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(12, 6))
plt.title("Özellik Önem Dereceleri (Feature Importances)")
plt.bar(range(len(importances)), importances[indices], align='center')
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)
plt.tight_layout()
plt.show()


# -----------------------------------------------
# 4. Precision-Recall Eğrisi
# -----------------------------------------------
plt.figure(figsize=(10, 8))
for i in range(len(class_names)):
    precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])
    disp = PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=auc(recall, precision))
    plt.plot(recall, precision, lw=2, label=f'{class_names[i]}')

plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Eğrisi (Multi-class)')
plt.legend(loc='best')
plt.show()

